# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS
# DATE: 16.9.2025
# REGISTRATION NO: 212222080013

# AIM

To test and compare how ChatGPT responds to Naïve (broad, unstructured) prompts versus Basic (clear, refined, structured) prompts across multiple scenarios. The experiment aims to analyze the quality, accuracy, and depth of responses and determine how prompt clarity influences output performance.

# ALGORITHM

Define Prompt Types:

Naïve Prompt: Short, unclear, lacks context or structure.

Basic Prompt: Detailed, structured, task-specific.

Select Test Scenarios:
Choose at least four scenarios:

Creative story generation

Factual question

Summary of concept

Advice/recommendation

Design Prompts:
For each scenario, write:

One naïve prompt

One basic prompt

Run Experiment:
Enter naïve prompt → record output
Enter basic prompt → record output

Compare Outputs:
Evaluate each pair using:

Quality

Accuracy

Depth

Tabulate Findings:
Prepare a comparison table listing both prompts and outputs.

Analyze:
Identify which prompt type performed better and why.

Conclusion/Result:
Summarize how prompt clarity affects ChatGPT’s performance.

# TEST SCENARIOS, PROMPTS, OUTPUTS, AND ANALYSIS
# SCENARIO 1: CREATIVE STORY
Naïve Prompt

“Write a story.”

Output (Naïve)

A very short, generic story with no theme or characters defined.

Basic Prompt

“Write a 150-word imaginative story about a young girl who discovers a hidden city under the ocean. Include emotions, conflict, and a hopeful ending.”

Output (Basic)

A detailed, structured story with defined characters, emotional depth, conflict, and resolution.

Analysis

Naïve prompt: Too broad, results in short, low-depth story.

Basic prompt: Specific instructions lead to richer storytelling, more coherence, better creativity.

# SCENARIO 2: FACTUAL QUESTION
Naïve Prompt

“What is AI?”

Output (Naïve)

A brief 2–3 line definition without technical breakdown.

Basic Prompt

“Explain Artificial Intelligence in 5–6 sentences, including definition, examples, real-world applications, and its importance in modern technology.”

Output (Basic)

Clear definition, examples like ML, NLP, robotics, applications in healthcare, finance, autonomous systems, and significance in automation.

Analysis

Naïve prompt: Minimal explanation, lacks depth and examples.

Basic prompt: Complete, structured, informative.

# SCENARIO 3: SUMMARY OF A CONCEPT
Naïve Prompt

“Summarize blockchain.”

Output (Naïve)

A short 3–4 line generic summary.

Basic Prompt

“Summarize the concept of blockchain in simple language within 120 words. Include definition, how it works, and one example.”

Output (Basic)

Easy-to-understand explanation with key elements like distributed ledger, blocks, hashing, transparency, and example (e.g., Bitcoin).

Analysis

Naïve prompt: Lacks coverage of core mechanisms.

Basic prompt: More structured, helps model include working principles and examples.

# SCENARIO 4: ADVICE OR RECOMMENDATION
Naïve Prompt

“Give me advice.”

Output (Naïve)

Generic motivational advice with no context.

Basic Prompt

“Suggest 5 practical study tips for an engineering student preparing for semester exams. Keep it realistic and actionable.”

Output (Basic)

Focused tips like making timetables, using active recall, practicing past papers, time management, and breaks.

Analysis

Naïve prompt: Irrelevant and broad.

Basic prompt: Personalized, practical, scenario-based advice.

# OVERALL ANALYSIS
Does ChatGPT perform better with basic prompts?

✔ Yes.
Basic prompts consistently produced:

Higher clarity

More detailed content

Better structured responses

Higher accuracy

More relevance

Did naïve prompts ever match basic prompts?

✘ No, except in very simple tasks.
Naïve prompts gave:

Generic responses

Missing structure

Lower creativity and accuracy

Lack of specificity

Key Insight

The model performs best when instructions are clear, structured, and contextual.

# RESULT

The experiment successfully demonstrated that basic, well-structured prompts produce significantly better quality, accuracy, and depth in ChatGPT’s responses compared to naïve prompts. Thus, prompt clarity plays a crucial role in optimizing AI output effectiveness.
